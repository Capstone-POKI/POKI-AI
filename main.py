# main.py
"""
í†µí•© Document AI + LayoutLM íŒŒì´í”„ë¼ì¸
"""

import os
from pathlib import Path
from typing import Dict, List, Optional

from src.utils.io_utils import save_json, read_json
# pdf_splitì€ ì´ì œ processor.py ë‚´ë¶€ ë¡œì§ì„ ë”°ë¥´ë¯€ë¡œ, ì§ì ‘ importí•  í•„ìš”ê°€ ì—†ê±°ë‚˜ 
# ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ í•„ìš”í•˜ë‹¤ë©´ ë‹¨ìˆœ ìœ í‹¸ë¡œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
from src.utils.pdf_split import split_pdf 

from src.document_ai.processor import (
    process_document,
    process_pdf_ocr_in_chunks,
    merge_chunk_results
)
from src.layoutlm.preprocess import (
    prepare_layoutlm_input,
    load_docai_json,
    get_labels,
    get_label_info,
    print_label_statistics
)
from src.layoutlm.inference import run_inference, aggregate_entities
from src.layoutlm.config import LAYOUTLM_MODEL_PATH


INPUT_DIR = "data/input"
OUTPUT_DIR = "data/output"


def detect_document_type(docai_result: Dict) -> str:
    """Document AI ê²°ê³¼ë¡œ ë¬¸ì„œ íƒ€ìž… ì¶”ì •"""
    
    metadata = docai_result.get("metadata", {})
    detected_sections = metadata.get("detected_sections", [])
    full_text = docai_result.get("text", "")
    
    # ê³µê³ ë¬¸ íŒ¨í„´
    if "ì˜ˆì‚°" in full_text or "ë°œì£¼ê¸°ê´€" in full_text or "ìž…ì°°" in full_text:
        return "notice"
    
    # Pitch Deck íŒ¨í„´
    section_keywords = ["background", "problem", "solution", "team", "market"]
    if any(s in detected_sections for s in section_keywords):
        return "pitch_deck"
    
    # IR Deck íŒ¨í„´
    numbers = docai_result.get("extracted_numbers", {})
    currency_count = len(numbers.get("currency", []))
    if currency_count >= 5:
        return "ir_deck"
    
    return "pitch_deck"


def run_document_ai_pipeline(
    pdf_path: str,
    processor_type: str = "OCR",
    output_path: Optional[str] = None,
    enable_enhancement: bool = True,
    use_chunking: bool = False,
    pages_per_chunk: int = 15
) -> Dict:
    """Document AI ì‹¤í–‰ (ë‹¨ì¼ ë˜ëŠ” ì²­í¬ ì²˜ë¦¬)"""
    
    print("\n" + "=" * 80)
    print("ðŸ“„ Step 1: Document AI ì²˜ë¦¬")
    print("=" * 80)
    
    pdf_name = Path(pdf_path).stem
    
    if not output_path:
        output_path = os.path.join(OUTPUT_DIR, f"{pdf_name}_docai_{processor_type.lower()}.json")
    
    if use_chunking:
        chunk_dir = os.path.join(OUTPUT_DIR, f"{pdf_name}_chunks")
        chunk_results = process_pdf_ocr_in_chunks(
            file_path=pdf_path,
            output_dir=chunk_dir,
            pages_per_chunk=pages_per_chunk,
            enable_enhancement=enable_enhancement
        )
        
        result = merge_chunk_results(chunk_results, output_path)
    else:
        result = process_document(
            file_path=pdf_path,
            processor_type=processor_type,
            output_path=output_path,
            enable_enhancement=enable_enhancement
        )
    
    if enable_enhancement and "metadata" in result:
        print(f"\nðŸ“Š Document AI ë¶„ì„ ê²°ê³¼:")
        metadata = result["metadata"]
        print(f"  - ì´ íŽ˜ì´ì§€: {metadata.get('total_pages', 0)}ê°œ")
        print(f"  - ê°ì§€ëœ ì„¹ì…˜: {', '.join(metadata.get('detected_sections', []))}")
        
        numbers = result.get("extracted_numbers", {})
        total_numbers = sum(len(v) for v in numbers.values())
        print(f"  - ì¶”ì¶œëœ ìˆ«ìž: {total_numbers}ê°œ")
        
        if numbers.get("currency"):
            print(f"    â€¢ í™”í: {[n['text'] for n in numbers['currency'][:3]]}")
        if numbers.get("percentage"):
            print(f"    â€¢ ë°±ë¶„ìœ¨: {[n['text'] for n in numbers['percentage'][:3]]}")
    
    return result


def run_layoutlm_pipeline(
    pdf_path: str,
    docai_json_path: str,
    doc_type: Optional[str] = None,
    output_dir: Optional[str] = None
) -> Dict:
    """LayoutLM ë¶„ì„ ì‹¤í–‰"""
    
    print("\n" + "=" * 80)
    print("ðŸ¤– Step 2: LayoutLM ì—”í‹°í‹° ì¶”ì¶œ")
    print("=" * 80)
    
    docai_result = load_docai_json(docai_json_path)
    
    if not doc_type:
        doc_type = detect_document_type(docai_result)
        print(f"  ðŸ” ë¬¸ì„œ íƒ€ìž… ìžë™ ê°ì§€: {doc_type}")
    else:
        print(f"  ðŸ“‹ ë¬¸ì„œ íƒ€ìž…: {doc_type}")
    
    labels = get_labels(doc_type)
    print(f"  ðŸ·ï¸ ì‚¬ìš© ë¼ë²¨: {len(labels)}ê°œ")
    
    from transformers import LayoutLMv3Processor
    
    # ðŸ”¥ [ìˆ˜ì •ë¨] apply_ocr=False ì˜µì…˜ ì¶”ê°€
    # Document AIê°€ ì´ë¯¸ OCR ì¢Œí‘œ(bbox)ë¥¼ ì œê³µí•˜ë¯€ë¡œ, LayoutLM ë‚´ë¶€ì˜ Tesseract OCRì„ ë•ë‹ˆë‹¤.
    processor = LayoutLMv3Processor.from_pretrained(
        "microsoft/layoutlmv3-base",
        apply_ocr=False
    )
    
    layoutlm_input = prepare_layoutlm_input(
        doc_json=docai_result,
        pdf_path=pdf_path,
        processor=processor,
        max_length=512
    )
    
    print(f"\n  ðŸŽ¯ LayoutLM ì¶”ë¡  ì‹¤í–‰...")
    print(f"  âš ï¸ ì£¼ì˜: ì‹¤ì œ ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ í•™ìŠµë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ê²°ê³¼ëŠ” ëžœë¤í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")
    
    # ì‹¤ì œ ì¶”ë¡  ë¡œì§ ì—°ê²° (ë”ë¯¸ ì‹¤í–‰)
    # í•™ìŠµëœ ëª¨ë¸ì´ ìžˆë‹¤ë©´ ì—¬ê¸°ì„œ run_inference()ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    # í˜„ìž¬ëŠ” ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì ê²€ìš©ìœ¼ë¡œ ìž…ë ¥ í˜•íƒœë§Œ í™•ì¸í•©ë‹ˆë‹¤.
    
    result = {
        "doc_type": doc_type,
        "num_labels": len(labels),
        "labels_sample": labels[:20],
        "input_shape": str(layoutlm_input["input_ids"].shape),
    }
    
    if not output_dir:
        output_dir = OUTPUT_DIR
    
    pdf_name = Path(pdf_path).stem
    result_path = os.path.join(output_dir, f"{pdf_name}_layoutlm_result.json")
    save_json(result, result_path)
    
    print(f"  âœ… ê²°ê³¼ ì €ìž¥: {result_path}\n")
    
    return result


def generate_comprehensive_report(
    pdf_path: str,
    docai_result: Dict,
    layoutlm_result: Dict,
    output_path: str
):
    """ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
    
    pdf_name = Path(pdf_path).stem
    
    with open(output_path, "w", encoding="utf-8") as f:
        f.write("=" * 80 + "\n")
        f.write(f"ðŸ“Š ë¬¸ì„œ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸\n")
        f.write("=" * 80 + "\n\n")
        
        f.write(f"ðŸ“„ ë¬¸ì„œëª…: {pdf_name}\n")
        f.write(f"ðŸ“‹ ë¬¸ì„œ íƒ€ìž…: {layoutlm_result.get('doc_type', 'unknown')}\n")
        f.write(f"ðŸ·ï¸ ì‚¬ìš© ë¼ë²¨ ìˆ˜: {layoutlm_result.get('num_labels', 0)}ê°œ\n\n")
        
        f.write("-" * 80 + "\n")
        f.write("ðŸ” Document AI ë¶„ì„ ê²°ê³¼\n")
        f.write("-" * 80 + "\n")
        
        metadata = docai_result.get("metadata", {})
        f.write(f"ì´ íŽ˜ì´ì§€: {metadata.get('total_pages', 0)}ê°œ\n")
        f.write(f"ì´ ë¸”ë¡: {metadata.get('total_blocks', 0)}ê°œ\n")
        f.write(f"ì´ ë¬¸ë‹¨: {metadata.get('total_paragraphs', 0)}ê°œ\n\n")
        
        detected_sections = docai_result.get("detected_sections", [])
        if detected_sections:
            f.write("ðŸ“ ê°ì§€ëœ ì„¹ì…˜:\n")
            for section in detected_sections:
                f.write(f"  â€¢ íŽ˜ì´ì§€ {section['page']}: {section['section']}\n")
                if 'preview' in section:
                    f.write(f"    {section['preview'][:80]}...\n")
            f.write("\n")
        
        numbers = docai_result.get("extracted_numbers", {})
        if numbers:
            f.write("ðŸ’° ì¶”ì¶œëœ ìˆ«ìž/í†µê³„:\n")
            
            if numbers.get("currency"):
                f.write(f"  í™”í ({len(numbers['currency'])}ê°œ):\n")
                for num in numbers["currency"][:10]:
                    f.write(f"    - {num['text']}\n")
            
            if numbers.get("percentage"):
                f.write(f"  ë°±ë¶„ìœ¨ ({len(numbers['percentage'])}ê°œ):\n")
                for num in numbers["percentage"][:10]:
                    f.write(f"    - {num['text']}\n")
            
            if numbers.get("quantity"):
                f.write(f"  ìˆ˜ëŸ‰ ({len(numbers['quantity'])}ê°œ):\n")
                for num in numbers["quantity"][:10]:
                    f.write(f"    - {num['text']}\n")
            f.write("\n")
        
        f.write("-" * 80 + "\n")
        f.write("ðŸ¤– LayoutLM ì—”í‹°í‹° ì¶”ì¶œ ê²°ê³¼\n")
        f.write("-" * 80 + "\n")
        f.write(f"ì‚¬ìš© ëª¨ë¸: LayoutLMv3\n")
        f.write(f"ìž…ë ¥ í˜•íƒœ: {layoutlm_result.get('input_shape', 'N/A')}\n")
        f.write(f"ë¼ë²¨ ìƒ˜í”Œ (20ê°œ):\n")
        for label in layoutlm_result.get('labels_sample', [])[:20]:
            f.write(f"  - {label}\n")
        
        f.write("\n" + "=" * 80 + "\n")
    
    print(f"ðŸ“„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output_path}")


def main():
    """ë©”ì¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    print("\n" + "=" * 80)
    print("ðŸš€ í†µí•© Document AI + LayoutLM íŒŒì´í”„ë¼ì¸")
    print("=" * 80)
    
    print_label_statistics()
    
    # ì˜ˆì œ 1: í”¼ì¹­ ìžë£Œ (ë‹¨ì¼ ì²˜ë¦¬)
    print("\n" + "=" * 80)
    print("ðŸ“„ ì˜ˆì œ 1: í”¼ì¹­ ìžë£Œ ë¶„ì„ (ë‹¨ì¼ ì²˜ë¦¬)")
    print("=" * 80)
    
    pitch_pdf = os.path.join(INPUT_DIR, "sample_pitch.pdf")
    
    if os.path.exists(pitch_pdf):
        docai_result = run_document_ai_pipeline(
            pdf_path=pitch_pdf,
            processor_type="OCR",
            enable_enhancement=True,
            use_chunking=False
        )
        
        docai_json = os.path.join(OUTPUT_DIR, "sample_pitch_docai_ocr.json")
        layoutlm_result = run_layoutlm_pipeline(
            pdf_path=pitch_pdf,
            docai_json_path=docai_json,
            doc_type="pitch_deck"
        )
        
        report_path = os.path.join(OUTPUT_DIR, "sample_pitch_report.txt")
        generate_comprehensive_report(
            pdf_path=pitch_pdf,
            docai_result=docai_result,
            layoutlm_result=layoutlm_result,
            output_path=report_path
        )
    else:
        print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {pitch_pdf}")
    
    # ì˜ˆì œ 2: IR Deck (ì²­í¬ ì²˜ë¦¬)
    print("\n" + "=" * 80)
    print("ðŸ“„ ì˜ˆì œ 2: IR Deck ë¶„ì„ (ì²­í¬ ì²˜ë¦¬)")
    print("=" * 80)
    
    irdeck_pdf = os.path.join(INPUT_DIR, "sample_irdeck.pdf")
    
    if os.path.exists(irdeck_pdf):
        docai_result = run_document_ai_pipeline(
            pdf_path=irdeck_pdf,
            processor_type="OCR",
            enable_enhancement=True,
            use_chunking=True,
            pages_per_chunk=15
        )
        
        docai_json = os.path.join(OUTPUT_DIR, "sample_irdeck_docai_ocr.json")
        layoutlm_result = run_layoutlm_pipeline(
            pdf_path=irdeck_pdf,
            docai_json_path=docai_json,
            doc_type="ir_deck"
        )
        
        report_path = os.path.join(OUTPUT_DIR, "sample_irdeck_report.txt")
        generate_comprehensive_report(
            pdf_path=irdeck_pdf,
            docai_result=docai_result,
            layoutlm_result=layoutlm_result,
            output_path=report_path
        )
    else:
        print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {irdeck_pdf}")
    
    # ì˜ˆì œ 3: ê³µê³ ë¬¸
    print("\n" + "=" * 80)
    print("ðŸ“„ ì˜ˆì œ 3: ê³µê³ ë¬¸ ë¶„ì„")
    print("=" * 80)
    
    notice_pdf = os.path.join(INPUT_DIR, "sample_notice.pdf")
    
    if os.path.exists(notice_pdf):
        docai_result = run_document_ai_pipeline(
            pdf_path=notice_pdf,
            processor_type="OCR",
            enable_enhancement=True
        )
        
        docai_json = os.path.join(OUTPUT_DIR, "sample_notice_docai_ocr.json")
        layoutlm_result = run_layoutlm_pipeline(
            pdf_path=notice_pdf,
            docai_json_path=docai_json,
            doc_type="notice"
        )
        
        report_path = os.path.join(OUTPUT_DIR, "sample_notice_report.txt")
        generate_comprehensive_report(
            pdf_path=notice_pdf,
            docai_result=docai_result,
            layoutlm_result=layoutlm_result,
            output_path=report_path
        )
    else:
        print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {notice_pdf}")
    
    print("\n" + "=" * 80)
    print("âœ… ëª¨ë“  íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print("=" * 80)
    print(f"\nðŸ“ ê²°ê³¼ í™•ì¸: {OUTPUT_DIR}/")
    print(f"  - *_docai_ocr.json: Document AI ê²°ê³¼ (ê°•í™”)")
    print(f"  - *_layoutlm_result.json: LayoutLM ì—”í‹°í‹° ì¶”ì¶œ")
    print(f"  - *_report.txt: ì¢…í•© ë¦¬í¬íŠ¸")
    print(f"  - *_chunks/: ì²­í¬ ì²˜ë¦¬ ê²°ê³¼ (ëŒ€ìš©ëŸ‰ PDF)\n")


def batch_process_documents(
    pdf_list: List[str],
    doc_type: Optional[str] = None,
    use_chunking: bool = False
):
    """ì—¬ëŸ¬ ë¬¸ì„œ ë°°ì¹˜ ì²˜ë¦¬"""
    
    print(f"\nðŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì‹œìž‘: {len(pdf_list)}ê°œ ë¬¸ì„œ")
    
    results = []
    
    for idx, pdf_path in enumerate(pdf_list, 1):
        print(f"\n{'='*80}")
        print(f"ðŸ“„ [{idx}/{len(pdf_list)}] {Path(pdf_path).name}")
        print(f"{'='*80}")
        
        try:
            docai_result = run_document_ai_pipeline(
                pdf_path=pdf_path,
                processor_type="OCR",
                enable_enhancement=True,
                use_chunking=use_chunking
            )
            
            pdf_name = Path(pdf_path).stem
            docai_json = os.path.join(OUTPUT_DIR, f"{pdf_name}_docai_ocr.json")
            
            layoutlm_result = run_layoutlm_pipeline(
                pdf_path=pdf_path,
                docai_json_path=docai_json,
                doc_type=doc_type
            )
            
            report_path = os.path.join(OUTPUT_DIR, f"{pdf_name}_report.txt")
            generate_comprehensive_report(
                pdf_path, docai_result, layoutlm_result, report_path
            )
            
            results.append({
                "pdf": pdf_path,
                "status": "success",
                "doc_type": layoutlm_result.get("doc_type")
            })
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            results.append({
                "pdf": pdf_path,
                "status": "failed",
                "error": str(e)
            })
    
    print(f"\n{'='*80}")
    print(f"ðŸ“Š ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ")
    print(f"{'='*80}")
    
    success = sum(1 for r in results if r["status"] == "success")
    failed = sum(1 for r in results if r["status"] == "failed")
    
    print(f"âœ… ì„±ê³µ: {success}/{len(pdf_list)}")
    print(f"âŒ ì‹¤íŒ¨: {failed}/{len(pdf_list)}")
    
    if failed > 0:
        print(f"\nì‹¤íŒ¨í•œ ë¬¸ì„œ:")
        for r in results:
            if r["status"] == "failed":
                print(f"  - {Path(r['pdf']).name}: {r['error']}")
    
    return results


if __name__ == "__main__":
    main()